{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Andrii\\miniconda3\\envs\\image_retrieval\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import faiss\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as T\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import timm\n",
    "\n",
    "from utils.data import get_loaders\n",
    "from utils.metrics import mean_average_precision_at_k\n",
    "from utils.constants import TRAIN_CSV, TEST_CSV, TRAIN_DIR, TEST_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_processor = AutoImageProcessor.from_pretrained(\"facebook/dinov2-base\")\n",
    "# model = Dinov2Model.from_pretrained(\"facebook/dinov2-base\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Andrii\\\\Data\\\\_UNIVER\\\\UCU\\\\3 sem\\\\CV\\\\image_retrieval\\\\data\\\\train.csv'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders_params = { \n",
    "    'batch_size': 64,\n",
    "    'num_workers': 8,\n",
    "    'pin_memory': False,\n",
    "    'persistent_workers': True,\n",
    "}\n",
    "train_loader, val_loader, test_loader = get_loaders(**loaders_params,\n",
    "                                                    train_transforms=T.Compose([\n",
    "                                                        T.Resize(224, interpolation=T.InterpolationMode.BICUBIC),\n",
    "                                                        T.CenterCrop((224, 224)),\n",
    "                                                        T.ToTensor(),\n",
    "                                                        T.Normalize(mean=torch.tensor([0.4815, 0.4578, 0.4082]),\n",
    "                                                                    std=torch.tensor([0.2686, 0.2613, 0.2758])),\n",
    "                                                    ]),\n",
    "                                                    test_transforms=T.Compose([\n",
    "                                                        T.Resize(224, interpolation=T.InterpolationMode.BICUBIC),\n",
    "                                                        T.CenterCrop((224, 224)),\n",
    "                                                        T.ToTensor(),\n",
    "                                                        T.Normalize(mean=torch.tensor([0.4815, 0.4578, 0.4082]),\n",
    "                                                                    std=torch.tensor([0.2686, 0.2613, 0.2758])),\n",
    "                                                    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = image_processor(image_torch, return_tensors=\"pt\")\n",
    "# inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = outputs.pooler_output.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model('vit_huge_patch14_clip_224.laion2b_ft_in12k_in1k', \n",
    "                          pretrained=True,\n",
    "                          features_only=True,\n",
    "                          in_chans=3).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageEmbedding(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.avgpool = torch.nn.AdaptiveAvgPool2d((1, 1))\n",
    "    \n",
    "    def __call__(self, images):\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(images)[-1]\n",
    "        embeddings = self.avgpool(outputs).squeeze(dim=(2, 3))\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ImageEmbedding(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexFlatL2(1280)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df = pd.DataFrame(columns=[\"embedding\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [03:12<00:00,  3.57s/it]\n"
     ]
    }
   ],
   "source": [
    "for images, labels in tqdm(train_loader):\n",
    "    images = images.to('cuda')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "\n",
    "    embeddings = outputs.cpu().numpy()\n",
    "\n",
    "    embeddings /= np.linalg.norm(embeddings, axis=1, ord=2, keepdims=True)\n",
    "\n",
    "    index.add(embeddings)\n",
    "\n",
    "    info_df = pd.concat([info_df, pd.DataFrame({\"embedding\": embeddings.tolist(), \"label\": labels.tolist()})]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0 2314  304 1181]\n",
      " [   1 2865  134 3066]\n",
      " [   2 2200  896    7]\n",
      " [   3 3241 2984 2213]\n",
      " [   4 1197 1496 1107]]\n",
      "[[0.         0.00128143 0.00200144 0.01544471]\n",
      " [0.         0.01015058 0.01032665 0.0117109 ]\n",
      " [0.         0.02443112 0.02501391 0.02663725]\n",
      " [0.         0.01678016 0.01730005 0.01756703]\n",
      " [0.         0.01157962 0.01968325 0.03675397]]\n"
     ]
    }
   ],
   "source": [
    "k = 4                          # we want to see 4 nearest neighbors\n",
    "D, I = index.search(np.stack(info_df.iloc[:5, 0]), k) # sanity check\n",
    "print(I)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>[0.005622134543955326, 0.004532663617283106, 0...</td>\n",
       "      <td>836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2120</th>\n",
       "      <td>[0.007937784306704998, 0.0008269997197203338, ...</td>\n",
       "      <td>992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>[0.007390028331428766, -0.001740914536640048, ...</td>\n",
       "      <td>810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>[0.006732639390975237, 0.0004799966118298471, ...</td>\n",
       "      <td>982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2974</th>\n",
       "      <td>[0.01100267842411995, 0.0006617089384235442, 0...</td>\n",
       "      <td>971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>[0.008517772890627384, 0.002008906565606594, 0...</td>\n",
       "      <td>372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>[0.012292384169995785, 0.0008968514739535749, ...</td>\n",
       "      <td>913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>[0.006986198481172323, -6.0722744819941e-05, 0...</td>\n",
       "      <td>931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>[0.011624250560998917, 0.004361431114375591, 0...</td>\n",
       "      <td>943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3233</th>\n",
       "      <td>[0.007222332991659641, 0.005141196306794882, 0...</td>\n",
       "      <td>857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              embedding label\n",
       "1475  [0.005622134543955326, 0.004532663617283106, 0...   836\n",
       "2120  [0.007937784306704998, 0.0008269997197203338, ...   992\n",
       "1917  [0.007390028331428766, -0.001740914536640048, ...   810\n",
       "1029  [0.006732639390975237, 0.0004799966118298471, ...   982\n",
       "2974  [0.01100267842411995, 0.0006617089384235442, 0...   971\n",
       "...                                                 ...   ...\n",
       "936   [0.008517772890627384, 0.002008906565606594, 0...   372\n",
       "640   [0.012292384169995785, 0.0008968514739535749, ...   913\n",
       "1743  [0.006986198481172323, -6.0722744819941e-05, 0...   931\n",
       "292   [0.011624250560998917, 0.004361431114375591, 0...   943\n",
       "3233  [0.007222332991659641, 0.005141196306794882, 0...   857\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_df.iloc[I[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:32<00:00, 10.76s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6325"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels = []\n",
    "all_preds = []\n",
    "all_class_lengths = []\n",
    "for images, labels in tqdm(val_loader):\n",
    "    images = images.to('cuda')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "\n",
    "    embeddings = outputs.cpu().numpy()\n",
    "\n",
    "    embeddings /= np.linalg.norm(embeddings, axis=1, ord=2, keepdims=True)\n",
    "\n",
    "    D, I = index.search(embeddings, 100)\n",
    "    all_labels.append(labels.numpy())\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        class_ids_top100 = info_df.iloc[I[i], 1].values\n",
    "        place_values = np.array([0.95**i for i in range(100)])\n",
    "        preds = np.zeros(1200) #np.ones(1200) * np.inf\n",
    "        for j in reversed(range(100)):\n",
    "            preds[class_ids_top100[j]] = place_values[j]\n",
    "        \n",
    "        all_preds.append(preds)\n",
    "        try:\n",
    "            label_pos = np.where(class_ids_top100 == labels[i].item())[0][0]\n",
    "            all_class_lengths.append(D[i, label_pos])\n",
    "        except:\n",
    "            all_class_lengths.append(10000)\n",
    "        # all_class_lengths.append(preds[labels[i].item()])\n",
    "    \n",
    "\n",
    "all_labels = np.concatenate(all_labels)\n",
    "all_preds = np.stack(all_preds)\n",
    "\n",
    "mean_average_precision_at_k(all_labels, all_preds, k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_class_lengths = np.array(all_class_lengths)\n",
    "plt.hist(all_class_lengths[all_class_lengths < 100000], bins=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- IP index, normalized: 0.6307\n",
    "- L2 index, unnormalized: 0.6151\n",
    "- L2 index, normalized: 0.6325"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01533740758895874"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(all_class_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:09<00:00,  3.09s/it]\n"
     ]
    }
   ],
   "source": [
    "for images, labels in tqdm(val_loader):\n",
    "    images = images.to('cuda')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "\n",
    "    embeddings = outputs.cpu().numpy()\n",
    "\n",
    "    embeddings /= np.linalg.norm(embeddings, axis=1, ord=2, keepdims=True)\n",
    "\n",
    "    index.add(embeddings)\n",
    "\n",
    "    info_df = pd.concat([info_df, pd.DataFrame({\"embedding\": embeddings.tolist(), \"label\": labels.tolist()})]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 205/205 [11:26<00:00,  3.35s/it]\n"
     ]
    }
   ],
   "source": [
    "test_preds = []\n",
    "for images in tqdm(test_loader):\n",
    "    images = images.to('cuda')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "\n",
    "    embeddings = outputs.cpu().numpy()\n",
    "\n",
    "    embeddings /= np.linalg.norm(embeddings, axis=1, ord=2, keepdims=True)\n",
    "\n",
    "    D, I = index.search(embeddings, 100)\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        class_ids_top100 = info_df.iloc[I[i], 1].values\n",
    "        preds = np.ones(1200) * np.inf\n",
    "        # preds = np.zeros(1200)\n",
    "        for j in reversed(range(100)):\n",
    "            preds[class_ids_top100[j]] = D[i, j]\n",
    "        \n",
    "        top_classes = np.argsort(preds)[:5] # [::-1][:5]\n",
    "        top_classes_dists = preds[top_classes]\n",
    "\n",
    "        # set -1 on the first place after THRESHOLD\n",
    "        cutoff_location = np.sum(preds < THRESHOLD)\n",
    "        if cutoff_location < 5:\n",
    "            for j in range(1, 5 - cutoff_location):\n",
    "                top_classes[5 - j] = top_classes[5 - j - 1]\n",
    "            top_classes[cutoff_location] = -1\n",
    "\n",
    "        test_preds.append(top_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(TEST_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['class'] = [' '.join([str(el) for el in classes]) for classes in test_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[['file_id', 'class']].to_csv('../submissions/vit_clip_l2_norm_thresh0.2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 205/205 [11:04<00:00,  3.24s/it]\n"
     ]
    }
   ],
   "source": [
    "test_preds = []\n",
    "for images in tqdm(test_loader):\n",
    "    images = images.to('cuda')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "\n",
    "    embeddings = outputs.cpu().numpy()\n",
    "\n",
    "    embeddings /= np.linalg.norm(embeddings, axis=1, ord=2, keepdims=True)\n",
    "\n",
    "    D, I = index.search(embeddings, 100)\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        class_ids_top100 = info_df.iloc[I[i], 1].values\n",
    "        preds = np.ones(1200) * np.inf\n",
    "        # preds = np.zeros(1200)\n",
    "        for j in reversed(range(100)):\n",
    "            preds[class_ids_top100[j]] = D[i, j]\n",
    "        \n",
    "        top_classes = np.argsort(preds)[:5] # [::-1][:5]\n",
    "        top_classes_dists = preds[top_classes]\n",
    "\n",
    "        test_preds.append(top_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['512x512'] = test_df['file_id'].apply(lambda file_id: (Image.open(os.path.join(TEST_DIR, f'{file_id}.jpg')).size) == (512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['class'] = [[str(el) for el in classes] for classes in test_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.loc[test_df['512x512'], 'class'] = test_df.loc[test_df['512x512'], 'class'].apply(lambda classes: '-1 ' + ' '.join(classes[:-1]))\n",
    "test_df.loc[~test_df['512x512'], 'class'] = test_df.loc[~test_df['512x512'], 'class'].apply(lambda classes: ' '.join(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[['file_id', 'class']].to_csv('../submissions/vit_clip_l2_norm_leak.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image_retrieval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
